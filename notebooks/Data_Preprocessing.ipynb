{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '/workspace/COMP3610-Renewable-Energy-Prediction/data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure processed directory exists\n",
    "processed_dir = '../data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country_data(country):\n",
    "    \"\"\"Load raw data for a specific country\"\"\"\n",
    "    file_path = f'../data/raw/{country}_Power_Generation.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {country} data with shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions to Clean each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_france_data(df):\n",
    "    # Handle 'n/e' values in object columns (convert to NaN then handle)\n",
    "    object_cols = df.select_dtypes(include='object').columns[4:]  # Skip Area, MTU, DATETIME\n",
    "    df[object_cols] = df[object_cols].replace('n/e', np.nan)\n",
    "    \n",
    "    # Convert object columns that should be numeric\n",
    "    for col in object_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            # For columns that are truly categorical (like Nuclear which is all 'n/e')\n",
    "            df = df.drop(col, axis=1)\n",
    "    \n",
    "    # Parse datetime properly\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format='%d.%m.%Y %H:%M')\n",
    "    df['MTU_start'] = pd.to_datetime(df['MTU'].str.split(' - ').str[0], format='%d.%m.%Y %H:%M')\n",
    "    \n",
    "    # Handle missing values - different strategies per column\n",
    "    # For columns with <5% missing (most columns)\n",
    "    cols_under_5 = [col for col in df.columns if df[col].isnull().mean() < 0.05 and df[col].dtype in ['float64', 'int64']]\n",
    "    df[cols_under_5] = df[cols_under_5].interpolate(method='time')\n",
    "    \n",
    "    # For columns with high missingness (Hydro Pumped Storage)\n",
    "    cols_over_50 = ['Hydro Pumped Storage  - Actual Aggregated [MW]', \n",
    "                   'Hydro Pumped Storage  - Actual Consumption [MW]']\n",
    "    df[cols_over_50] = df[cols_over_50].fillna(0)  # Assuming no pumping when data missing\n",
    "    \n",
    "    # Feature engineering\n",
    "    df['hour'] = df['DATETIME'].dt.hour\n",
    "    df['day_of_week'] = df['DATETIME'].dt.dayofweek\n",
    "    df['month'] = df['DATETIME'].dt.month\n",
    "    df['season'] = (df['month'] % 12 + 3) // 3\n",
    "    \n",
    "    # 6. Calculate total renewable energy (focus of our prediction)\n",
    "    renewable_cols = ['Solar  - Actual Aggregated [MW]', \n",
    "                     'Wind Onshore  - Actual Aggregated [MW]',\n",
    "                     'Wind Offshore  - Actual Aggregated [MW]',\n",
    "                     'Hydro Run-of-river and poundage  - Actual Aggregated [MW]',\n",
    "                     'Hydro Water Reservoir  - Actual Aggregated [MW]']\n",
    "    \n",
    "    df['Total_Renewable'] = df[renewable_cols].sum(axis=1)\n",
    "    \n",
    "    # 7. Select and rename columns\n",
    "    columns_to_keep = [\n",
    "        \"Area\", \n",
    "        \"MTU\", \n",
    "        \"DATETIME\", \n",
    "        \"YEAR\", \n",
    "        \"Solar  - Actual Aggregated [MW]\", \n",
    "        \"Wind Offshore  - Actual Aggregated [MW]\", \n",
    "        \"Wind Onshore  - Actual Aggregated [MW]\"\n",
    "    ]\n",
    "\n",
    "    # Select all columns except the ones to keep\n",
    "    columns_to_drop = [col for col in df.columns if col not in columns_to_keep]\n",
    "\n",
    "    # Drop those columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_italy_data(df):\n",
    "    # 1. Handle 'n/e' values\n",
    "    object_cols = df.select_dtypes(include='object').columns[4:]\n",
    "    df[object_cols] = df[object_cols].replace('n/e', np.nan)\n",
    "    \n",
    "    # 2. Nuclear is all 'n/e' - drop\n",
    "    df = df.drop('Nuclear  - Actual Aggregated [MW]', axis=1)\n",
    "    \n",
    "    # 3. Parse datetime\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format='%d.%m.%Y %H:%M')\n",
    "    \n",
    "    # 4. Handle missing values\n",
    "    # Fossil Coal-derived gas has 575 missing - inspect pattern\n",
    "    if df['Fossil Coal-derived gas  - Actual Aggregated [MW]'].isnull().sum() > 0:\n",
    "        df['Fossil Coal-derived gas  - Actual Aggregated [MW]'] = df['Fossil Coal-derived gas  - Actual Aggregated [MW]'].fillna(0)\n",
    "    \n",
    "    # Other columns with minimal missingness\n",
    "    cols_under_5 = [col for col in df.columns if df[col].isnull().mean() < 0.05 and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    df[cols_under_5] = df[cols_under_5].interpolate(method='time')\n",
    "    \n",
    "    # High missingness columns\n",
    "    df['Hydro Pumped Storage  - Actual Consumption [MW]'] = df['Hydro Pumped Storage  - Actual Consumption [MW]'].fillna(0)\n",
    "    \n",
    "    # 5. Feature engineering\n",
    "    df['hour'] = df['DATETIME'].dt.hour\n",
    "    df['day_of_week'] = df['DATETIME'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "    \n",
    "    # 6. Total renewable calculation\n",
    "    renewable_cols = ['Solar  - Actual Aggregated [MW]',\n",
    "                    'Wind Onshore  - Actual Aggregated [MW]',\n",
    "                    'Geothermal  - Actual Aggregated [MW]',\n",
    "                    'Hydro Run-of-river and poundage  - Actual Aggregated [MW]']\n",
    "    \n",
    "    df['Total_Renewable'] = df[renewable_cols].sum(axis=1)\n",
    "    \n",
    "    # 7. Select and rename columns\n",
    "    columns_to_keep = [\n",
    "        \"Area\", \n",
    "        \"MTU\", \n",
    "        \"DATETIME\", \n",
    "        \"YEAR\", \n",
    "        \"Solar  - Actual Aggregated [MW]\", \n",
    "        \"Wind Offshore  - Actual Aggregated [MW]\", \n",
    "        \"Wind Onshore  - Actual Aggregated [MW]\"\n",
    "    ]\n",
    "\n",
    "    # Select all columns except the ones to keep\n",
    "    columns_to_drop = [col for col in df.columns if col not in columns_to_keep]\n",
    "\n",
    "    # Drop those columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spain_data(df):\n",
    "    # Spain data is mostly numeric already\n",
    "    \n",
    "    # 1. Parse datetime\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format='%d.%m.%Y %H:%M')\n",
    "    \n",
    "    # 2. Handle missing values (mostly minimal)\n",
    "    cols_with_missing = [col for col in df.columns if df[col].isnull().sum() > 0 and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    for col in cols_with_missing:\n",
    "        if df[col].isnull().mean() < 0.01:  # Less than 1% missing\n",
    "            df[col] = df[col].interpolate(method='time')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(0)  # For columns like Marine which are mostly 0\n",
    "    \n",
    "    # 3. Feature engineering\n",
    "    df['hour'] = df['DATETIME'].dt.hour\n",
    "    df['month'] = df['DATETIME'].dt.month\n",
    "    df['season'] = (df['month'] % 12 + 3) // 3\n",
    "    \n",
    "    # 4. Total renewable calculation\n",
    "    renewable_cols = ['Solar  - Actual Aggregated [MW]',\n",
    "                     'Wind Onshore  - Actual Aggregated [MW]',\n",
    "                     'Wind Offshore  - Actual Aggregated [MW]',\n",
    "                     'Hydro Run-of-river and poundage  - Actual Aggregated [MW]',\n",
    "                     'Hydro Water Reservoir  - Actual Aggregated [MW]']\n",
    "    \n",
    "    df['Total_Renewable'] = df[renewable_cols].sum(axis=1)\n",
    "    \n",
    "    # 7. Select and rename columns\n",
    "    columns_to_keep = [\n",
    "        \"Area\", \n",
    "        \"MTU\", \n",
    "        \"DATETIME\", \n",
    "        \"YEAR\", \n",
    "        \"Solar  - Actual Aggregated [MW]\", \n",
    "        \"Wind Offshore  - Actual Aggregated [MW]\", \n",
    "        \"Wind Onshore  - Actual Aggregated [MW]\"\n",
    "    ]\n",
    "\n",
    "    # Select all columns except the ones to keep\n",
    "    columns_to_drop = [col for col in df.columns if col not in columns_to_keep]\n",
    "\n",
    "    # Drop those columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Each Country's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing France data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/3655646536.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[object_cols] = df[object_cols].replace('n/e', np.nan)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time-weighted interpolation only works on Series or DataFrames with a DatetimeIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Clean data using the appropriate function\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m country \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrance\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 15\u001b[0m     cleaned_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_france_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m country \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItaly\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m     cleaned_df \u001b[38;5;241m=\u001b[39m clean_italy_data(raw_df)\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mclean_france_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Handle missing values - different strategies per column\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# For columns with <5% missing (most columns)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m cols_under_5 \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 21\u001b[0m df[cols_under_5] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_under_5\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# For columns with high missingness (Hydro Pumped Storage)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m cols_over_50 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHydro Pumped Storage  - Actual Aggregated [MW]\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     25\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHydro Pumped Storage  - Actual Consumption [MW]\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/generic.py:8499\u001b[0m, in \u001b[0;36mNDFrame.interpolate\u001b[0;34m(self, method, axis, limit, inplace, limit_direction, limit_area, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   8497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8498\u001b[0m     index \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mget_interp_index(method, obj\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 8499\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit_direction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_area\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8505\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8507\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8510\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   8511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_transpose:\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/internals/base.py:291\u001b[0m, in \u001b[0;36mDataManager.interpolate\u001b[0;34m(self, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minterpolate\u001b[39m(\u001b[38;5;28mself\u001b[39m, inplace: \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterpolate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1797\u001b[0m, in \u001b[0;36mBlock.interpolate\u001b[0;34m(self, method, index, inplace, limit, limit_direction, limit_area, downcast, using_cow, already_warned, **kwargs)\u001b[0m\n\u001b[1;32m   1794\u001b[0m copy, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_refs_and_copy(using_cow, inplace)\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;66;03m# Dispatch to the EA method.\u001b[39;00m\n\u001b[0;32m-> 1797\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_direction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_area\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1807\u001b[0m data \u001b[38;5;241m=\u001b[39m extract_array(new_values, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m copy\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m warn_copy_on_write()\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m already_warned \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m already_warned\u001b[38;5;241m.\u001b[39mwarned_already\n\u001b[1;32m   1814\u001b[0m ):\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/arrays/numpy_.py:296\u001b[0m, in \u001b[0;36mNumpyExtensionArray.interpolate\u001b[0;34m(self, method, axis, index, limit, limit_direction, limit_area, copy, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     out_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# TODO: assert we have floating dtype?\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[43mmissing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate_2d_inplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_direction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit_area\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/pandas/core/missing.py:373\u001b[0m, in \u001b[0;36minterpolate_2d_inplace\u001b[0;34m(data, index, axis, method, limit, limit_direction, limit_area, fill_value, mask, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(index\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    374\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime-weighted interpolation only works \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon Series or DataFrames with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m         )\n\u001b[1;32m    378\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m limit_direction \u001b[38;5;241m=\u001b[39m validate_limit_direction(limit_direction)\n",
      "\u001b[0;31mValueError\u001b[0m: time-weighted interpolation only works on Series or DataFrames with a DatetimeIndex"
     ]
    }
   ],
   "source": [
    "def clean_france_data(df):\n",
    "    # 1. First convert DATETIME to proper datetime and set as index\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format='%d.%m.%Y %H:%M')\n",
    "    df = df.set_index('DATETIME')\n",
    "    \n",
    "    # 2. Handle 'n/e' values in object columns (convert to NaN then handle)\n",
    "    object_cols = df.select_dtypes(include='object').columns[3:]  # Skip Area, MTU, YEAR\n",
    "    df[object_cols] = df[object_cols].replace('n/e', np.nan)\n",
    "    \n",
    "    # 3. Convert object columns that should be numeric\n",
    "    for col in object_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            # For columns that are truly categorical\n",
    "            df = df.drop(col, axis=1)\n",
    "    \n",
    "    # 4. Now handle missing values with time interpolation\n",
    "    cols_under_5 = [col for col in df.columns \n",
    "                   if df[col].isnull().mean() < 0.05 \n",
    "                   and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    \n",
    "    # Only interpolate if we have datetime index\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        df[cols_under_5] = df[cols_under_5].interpolate(method='time')\n",
    "    else:\n",
    "        df[cols_under_5] = df[cols_under_5].interpolate()\n",
    "    \n",
    "    # 5. Handle high missingness columns\n",
    "    cols_over_50 = ['Hydro Pumped Storage  - Actual Aggregated [MW]', \n",
    "                   'Hydro Pumped Storage  - Actual Consumption [MW]']\n",
    "    for col in cols_over_50:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0)\n",
    "    \n",
    "    # 6. Feature engineering\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df['season'] = (df['month'] % 12 + 3) // 3\n",
    "    \n",
    "    # 7. Calculate total renewable energy\n",
    "    renewable_cols = ['Solar  - Actual Aggregated [MW]', \n",
    "                     'Wind Onshore  - Actual Aggregated [MW]',\n",
    "                     'Wind Offshore  - Actual Aggregated [MW]',\n",
    "                     'Hydro Run-of-river and poundage  - Actual Aggregated [MW]',\n",
    "                     'Hydro Water Reservoir  - Actual Aggregated [MW]']\n",
    "    \n",
    "    df['Total_Renewable'] = df[renewable_cols].sum(axis=1)\n",
    "    \n",
    "    # 8. Drop unnecessary columns\n",
    "    drop_cols = ['MTU', 'Area', 'Fossil Peat  - Actual Aggregated [MW]', \n",
    "                'Marine  - Actual Aggregated [MW]']\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "    \n",
    "    return df.reset_index()  # Return with DATETIME as column again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined cleaned data to ../data/processed/EU_Power_Generation_Combined_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine all country data\n",
    "combined_df = pd.concat(cleaned_data.values())\n",
    "\n",
    "# Save combined data\n",
    "combined_path = f'{processed_dir}/EU_Power_Generation_Combined_Cleaned.csv'\n",
    "combined_df.to_csv(combined_path)\n",
    "print(f\"Saved combined cleaned data to {combined_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
